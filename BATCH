#!/bin/bash

# Copy/paste this job script into a text file and submit with the command:
#    sbatch thefilename
# job standard output will go to the file slurm-%j.out (where %j is the job ID)

#SBATCH --time=00:15:00   # walltime limit (HH:MM:SS)
#SBATCH --nodes=2   # number of nodes
#SBATCH --ntasks-per-node=2   # We use 2 tasks per node for this workload
#SBATCH --job-name="cuda_gemm"
#SBATCH --mem=96G   # maximum memory per node
#SBATCH --partition=instruction
#SBATCH --gres=gpu:a100:1

# LOAD MODULES, INSERT CODE, AND RUN YOUR PROGRAMS HERE

module load cuda openmpi

# run 3 threads per node
mpirun -np 2 ./mmult
echo $(hostname)

